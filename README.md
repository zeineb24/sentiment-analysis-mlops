# End-to-End Sentiment Analysis MLOps Pipeline (GCP)

This repository implements a **production-style end-to-end MLOps pipeline** for sentiment analysis using **Google Cloud Platform (GCP)**.  
It covers data preprocessing, model inference, CI/CD, batch prediction, and explainability, following modern MLOps best practices.

---

## ğŸš€ Project Overview

The goal of this project is to demonstrate how a machine learning model can be:
- trained and containerized,
- deployed as a scalable API,
- integrated into a **batch data processing pipeline**,
- monitored and tested using CI/CD,
- and explained using **XAI techniques**.

This project was built as part of an advanced MLOps workflow and reflects real-world ML system design.

---

## ğŸ—ï¸ Architecture
BigQuery / GCS
â†“
Apache Beam (Dataflow)
â†“
Vertex AI / Cloud Run Model Endpoint
â†“
Predictions stored in BigQuery
â†“
Explainability (SHAP)

## ğŸ§  Model
- Task: **Sentiment Analysis (binary classification)**
- Algorithms:
  - TF-IDF + Random Forest (scikit-learn)
- Evaluation metrics:
  - Accuracy
  - Precision / Recall
  - F1-score

---

## âš™ï¸ Tech Stack

- **Python**
- **Google Cloud Platform**
  - BigQuery
  - Cloud Storage (GCS)
  - Vertex AI
  - Cloud Run
  - Cloud Build
  - Dataflow
- **Apache Beam**
- **Docker**
- **scikit-learn**
- **SHAP** (Explainable AI)

---

## ğŸ“‚ Repository Structure

.
â”œâ”€â”€ beam_clean_pipeline.py # Data cleaning pipeline (Apache Beam)
â”œâ”€â”€ beam_pipeline_to_vertexai.py # Batch prediction pipeline
â”œâ”€â”€ predict.py # Model inference logic
â”œâ”€â”€ xai_ex.py # SHAP explainability
â”œâ”€â”€ Dockerfile # Containerized model
â”œâ”€â”€ cloudbuild.yaml # CI/CD pipeline (Cloud Build)
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ test_predict.py # Unit tests
â”œâ”€â”€ test_request.py # API request tests
â””â”€â”€ README.md

yaml
Copy code

---

## ğŸ”„ MLOps Features Implemented

âœ” Data preprocessing with **Apache Beam**  
âœ” Batch inference with **Vertex AI / Cloud Run**  
âœ” CI/CD automation using **Cloud Build**  
âœ” Containerized deployment with **Docker**  
âœ” Unit & integration testing  
âœ” Model explainability with **SHAP**  

---

## â–¶ï¸ How to Run (Locally)

```bash
pip install -r requirements.txt
python predict.py

